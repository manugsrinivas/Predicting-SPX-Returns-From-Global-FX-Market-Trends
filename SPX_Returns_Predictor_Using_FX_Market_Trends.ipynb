{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "r3NyQoRvmmPu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import yfinance as yf\n",
        "from datetime import datetime\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, TimeSeriesSplit, cross_val_score\n",
        "from sklearn.linear_model import LinearRegression, LassoCV\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cross_decomposition import PLSRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set plotting style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.dpi'] = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uW8Uex7qUtxz"
      },
      "source": [
        "#Data Scraping and formatting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nv5NraOrVkmo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "643c097a-3f41-4bbb-e7b3-0245bec23a62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[STEP 1] Downloading data from Yahoo Finance...\n",
            "  Downloading S&P 500...\n",
            "  ✓ S&P 500: 313 months\n",
            "  Downloading FX pairs...\n",
            "    ✓ exalus\n",
            "    ✓ exbzus\n",
            "    ✓ excaus\n",
            "    ✓ exchus\n",
            "    ✓ exdnus\n",
            "    ✓ exhkus\n",
            "    ✓ exinus\n",
            "    ✓ exjpus\n",
            "    ✓ exkous\n",
            "    ✓ exmxus\n",
            "    ✓ exmaus\n",
            "    ✓ exnzus\n",
            "    ✓ exnous\n",
            "    ✓ exsius\n",
            "    ✓ exsfus\n",
            "    ✓ exslus\n",
            "    ✓ exsdus\n",
            "    ✓ exszus\n",
            "    ✓ extaus\n",
            "    ✓ exthus\n",
            "    ✓ exukus\n",
            "    ✓ exeuus\n",
            "    ✓ exvzus\n",
            "  ✓ Downloaded 23 currency pairs\n",
            "\n",
            "  Aligning data...\n",
            "  Combined: (313, 24)\n",
            "  After dropna: (104, 24)\n",
            "  Date range: 2017-05-31 to 2026-01-31\n",
            "  ✓ Final dataset: 103 months\n",
            "  Date range: 2017-07-31 to 2026-01-31\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n[STEP 1] Downloading data from Yahoo Finance...\")\n",
        "\n",
        "START_DATE = '2000-01-01'\n",
        "END_DATE = datetime.now().strftime('%Y-%m-%d')\n",
        "\n",
        "# S&P 500\n",
        "print(\"  Downloading S&P 500...\")\n",
        "spx_ticker = yf.Ticker('^GSPC')\n",
        "spx_data = spx_ticker.history(start=START_DATE, end=END_DATE)\n",
        "spx_monthly = spx_data['Close'].resample('M').last()\n",
        "\n",
        "# CRITICAL FIX: Remove timezone to allow proper alignment\n",
        "spx_monthly.index = spx_monthly.index.tz_localize(None)\n",
        "spx_monthly.name = 'sp500'\n",
        "\n",
        "print(f\"  ✓ S&P 500: {len(spx_monthly)} months\")\n",
        "\n",
        "# FX pairs\n",
        "print(\"  Downloading FX pairs...\")\n",
        "fx_tickers = {\n",
        "    'AUDUSD=X': 'exalus', 'BRLUSD=X': 'exbzus', 'CADUSD=X': 'excaus',\n",
        "    'CNYUSD=X': 'exchus', 'DKKUSD=X': 'exdnus', 'HKDUSD=X': 'exhkus',\n",
        "    'INRUSD=X': 'exinus', 'JPYUSD=X': 'exjpus', 'KRWUSD=X': 'exkous',\n",
        "    'MXNUSD=X': 'exmxus', 'MYRUSD=X': 'exmaus', 'NZDUSD=X': 'exnzus',\n",
        "    'NOKUSD=X': 'exnous', 'SGDUSD=X': 'exsius', 'ZARUSD=X': 'exsfus',\n",
        "    'LKRUSD=X': 'exslus', 'SEKUSD=X': 'exsdus', 'CHFUSD=X': 'exszus',\n",
        "    'TWDUSD=X': 'extaus', 'THBUSD=X': 'exthus', 'GBPUSD=X': 'exukus',\n",
        "    'EURUSD=X': 'exeuus', 'VESUSD=X': 'exvzus',\n",
        "}\n",
        "\n",
        "fx_data = {}\n",
        "for ticker, col_name in fx_tickers.items():\n",
        "    try:\n",
        "        fx_ticker = yf.Ticker(ticker)\n",
        "        data = fx_ticker.history(start=START_DATE, end=END_DATE)\n",
        "\n",
        "        if len(data) > 0 and 'Close' in data.columns:\n",
        "            monthly = data['Close'].resample('M').last()\n",
        "\n",
        "            # CRITICAL FIX: Remove timezone\n",
        "            monthly.index = monthly.index.tz_localize(None)\n",
        "\n",
        "            # Invert if needed\n",
        "            if ticker.startswith(('AUD', 'EUR', 'GBP', 'NZD')):\n",
        "                fx_data[col_name] = 1 / monthly\n",
        "            else:\n",
        "                fx_data[col_name] = monthly\n",
        "\n",
        "            print(f\"    ✓ {col_name}\")\n",
        "    except Exception as e:\n",
        "        print(f\"    ✗ {col_name}: {str(e)[:40]}\")\n",
        "\n",
        "fx_monthly = pd.DataFrame(fx_data)\n",
        "print(f\"  ✓ Downloaded {len(fx_data)} currency pairs\")\n",
        "\n",
        "# Combine and clean\n",
        "print(\"\\n  Aligning data...\")\n",
        "combined = fx_monthly.join(spx_monthly, how='inner')\n",
        "print(f\"  Combined: {combined.shape}\")\n",
        "\n",
        "# Remove NaN\n",
        "combined = combined.dropna()\n",
        "print(f\"  After dropna: {combined.shape}\")\n",
        "print(f\"  Date range: {combined.index.min().date()} to {combined.index.max().date()}\")\n",
        "\n",
        "if len(combined) == 0:\n",
        "    raise ValueError(\"No data after alignment - check data sources\")\n",
        "\n",
        "# Separate\n",
        "fx_prices = combined.drop('sp500', axis=1)\n",
        "spx_prices = combined[['sp500']]\n",
        "\n",
        "# Calculate returns\n",
        "fx_returns = fx_prices.pct_change().iloc[1:]  # Drop first NaN row\n",
        "spx_returns = spx_prices.pct_change().iloc[1:]\n",
        "\n",
        "# Clean infinite values\n",
        "fx_returns = fx_returns.replace([np.inf, -np.inf], np.nan).dropna()\n",
        "spx_returns = spx_returns.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "# Ensure alignment\n",
        "common_idx = fx_returns.index.intersection(spx_returns.index)\n",
        "fx_returns = fx_returns.loc[common_idx]\n",
        "spx_returns = spx_returns.loc[common_idx]\n",
        "\n",
        "print(f\"  ✓ Final dataset: {len(fx_returns)} months\")\n",
        "print(f\"  Date range: {fx_returns.index.min().date()} to {fx_returns.index.max().date()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dor5cm4kWuOR"
      },
      "source": [
        "#Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2HQplemWxRS",
        "outputId": "4b29a78b-e23b-45de-a4bc-c9c051c9ede3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "[STEP 2] EXPLORATORY DATA ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "2.1 Basic Statistics\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "S&P 500 Returns:\n",
            "  Mean:       1.142% per month\n",
            "  Median:     1.936%\n",
            "  Std Dev:    4.599%\n",
            "  Skewness:  -0.509\n",
            "  Kurtosis:   0.460\n",
            "  Min:       -12.51%\n",
            "  Max:        12.68%\n",
            "\n",
            "FX Returns Summary:\n",
            "  Mean volatility:  404734.614%\n",
            "  Min volatility:   0.238% (exhkus)\n",
            "  Max volatility:   9308841.637% (exvzus)\n",
            "\n",
            "2.2 Correlation Analysis\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Highly correlated FX pairs (|r| > 0.7): 37\n",
            "\n",
            "Top 10 correlated pairs:\n",
            "  exdnus <-> exeuus: -0.9991\n",
            "  exalus <-> exnzus: +0.9033\n",
            "  exnzus <-> exsius: -0.8456\n",
            "  exnous <-> exsdus: +0.8418\n",
            "  exkous <-> exsius: +0.8275\n",
            "  exdnus <-> exsdus: +0.8234\n",
            "  exsdus <-> exeuus: -0.8189\n",
            "  exmaus <-> exsius: +0.8168\n",
            "  exmaus <-> exthus: +0.8090\n",
            "  exsius <-> exukus: -0.8083\n",
            "\n",
            "Top 5 FX correlations with S&P 500:\n",
            "  exnous: +0.6154\n",
            "  excaus: +0.5620\n",
            "  exsius: +0.5392\n",
            "  exsfus: +0.4824\n",
            "  exmxus: +0.4659\n",
            "\n",
            "Bottom 5 FX correlations with S&P 500:\n",
            "  exhkus: +0.0095\n",
            "  exeuus: -0.3214\n",
            "  exukus: -0.5497\n",
            "  exnzus: -0.5506\n",
            "  exalus: -0.6245\n",
            "\n",
            "Interpretation:\n",
            "  • High FX inter-correlations (37 pairs) suggest\n",
            "    that PCA will be effective at reducing dimensionality\n",
            "  • FX-SPX correlations range from -0.625 to +0.615\n",
            "\n",
            "2.3 Creating EDA Visualizations...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"[STEP 2] EXPLORATORY DATA ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 2.1 Basic Statistics\n",
        "print(\"\\n2.1 Basic Statistics\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "spx_ret = spx_returns['sp500']\n",
        "\n",
        "print(\"\\nS&P 500 Returns:\")\n",
        "print(f\"  Mean:     {spx_ret.mean()*100:>7.3f}% per month\")\n",
        "print(f\"  Median:   {spx_ret.median()*100:>7.3f}%\")\n",
        "print(f\"  Std Dev:  {spx_ret.std()*100:>7.3f}%\")\n",
        "print(f\"  Skewness: {spx_ret.skew():>7.3f}\")\n",
        "print(f\"  Kurtosis: {spx_ret.kurtosis():>7.3f}\")\n",
        "print(f\"  Min:      {spx_ret.min()*100:>7.2f}%\")\n",
        "print(f\"  Max:      {spx_ret.max()*100:>7.2f}%\")\n",
        "\n",
        "print(\"\\nFX Returns Summary:\")\n",
        "print(f\"  Mean volatility:  {fx_returns.std().mean()*100:.3f}%\")\n",
        "print(f\"  Min volatility:   {fx_returns.std().min()*100:.3f}% ({fx_returns.std().idxmin()})\")\n",
        "print(f\"  Max volatility:   {fx_returns.std().max()*100:.3f}% ({fx_returns.std().idxmax()})\")\n",
        "\n",
        "# 2.2 Correlation Analysis\n",
        "print(\"\\n2.2 Correlation Analysis\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "correlation_matrix = fx_returns.corr()\n",
        "\n",
        "# High correlations\n",
        "high_corr_pairs = []\n",
        "for i in range(len(correlation_matrix.columns)):\n",
        "    for j in range(i+1, len(correlation_matrix.columns)):\n",
        "        corr_val = correlation_matrix.iloc[i, j]\n",
        "        if abs(corr_val) > 0.7:\n",
        "            high_corr_pairs.append((\n",
        "                correlation_matrix.columns[i],\n",
        "                correlation_matrix.columns[j],\n",
        "                corr_val\n",
        "            ))\n",
        "\n",
        "print(f\"\\nHighly correlated FX pairs (|r| > 0.7): {len(high_corr_pairs)}\")\n",
        "if high_corr_pairs:\n",
        "    print(\"\\nTop 10 correlated pairs:\")\n",
        "    for curr1, curr2, corr in sorted(high_corr_pairs, key=lambda x: abs(x[2]), reverse=True)[:10]:\n",
        "        print(f\"  {curr1} <-> {curr2}: {corr:>+.4f}\")\n",
        "\n",
        "# Correlations with SPX\n",
        "spx_corr = fx_returns.corrwith(spx_ret).sort_values(ascending=False)\n",
        "\n",
        "print(f\"\\nTop 5 FX correlations with S&P 500:\")\n",
        "for curr, corr in spx_corr.head(5).items():\n",
        "    print(f\"  {curr}: {corr:>+.4f}\")\n",
        "\n",
        "print(f\"\\nBottom 5 FX correlations with S&P 500:\")\n",
        "for curr, corr in spx_corr.tail(5).items():\n",
        "    print(f\"  {curr}: {corr:>+.4f}\")\n",
        "\n",
        "print(f\"\\nInterpretation:\")\n",
        "print(f\"  • High FX inter-correlations ({len(high_corr_pairs)} pairs) suggest\")\n",
        "print(f\"    that PCA will be effective at reducing dimensionality\")\n",
        "print(f\"  • FX-SPX correlations range from {spx_corr.min():+.3f} to {spx_corr.max():+.3f}\")\n",
        "\n",
        "# 2.3 Create EDA Visualizations\n",
        "print(\"\\n2.3 Creating EDA Visualizations...\")\n",
        "\n",
        "fig = plt.figure(figsize=(20, 12))\n",
        "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
        "\n",
        "# Plot 1: FX Correlation Heatmap\n",
        "ax = fig.add_subplot(gs[0, :2])\n",
        "mask = np.triu(np.ones_like(correlation_matrix), k=1)\n",
        "sns.heatmap(correlation_matrix, mask=mask, cmap='coolwarm', center=0,\n",
        "            square=False, linewidths=0.5, cbar_kws={\"shrink\": 0.8},\n",
        "            ax=ax, vmin=-1, vmax=1, annot=False)\n",
        "ax.set_title('FX Returns Correlation Matrix', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Plot 2: FX-SPX Correlations\n",
        "ax = fig.add_subplot(gs[0, 2])\n",
        "colors = ['green' if x > 0 else 'red' for x in spx_corr.values]\n",
        "ax.barh(range(len(spx_corr)), spx_corr.values, color=colors, alpha=0.6)\n",
        "ax.set_yticks(range(len(spx_corr)))\n",
        "ax.set_yticklabels(spx_corr.index, fontsize=8)\n",
        "ax.set_xlabel('Correlation with SPX', fontsize=10)\n",
        "ax.set_title('FX Correlations with S&P 500', fontsize=12, fontweight='bold')\n",
        "ax.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
        "ax.grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# Plot 3: SPX Returns Distribution\n",
        "ax = fig.add_subplot(gs[1, 0])\n",
        "ax.hist(spx_ret, bins=30, edgecolor='black', alpha=0.7, color='darkblue')\n",
        "ax.axvline(spx_ret.mean(), color='red', linestyle='--', linewidth=2,\n",
        "           label=f'Mean: {spx_ret.mean()*100:.2f}%')\n",
        "ax.axvline(0, color='black', linestyle='-', linewidth=1)\n",
        "ax.set_xlabel('Monthly Return')\n",
        "ax.set_ylabel('Frequency')\n",
        "ax.set_title('S&P 500 Returns Distribution', fontsize=12, fontweight='bold')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 4: FX Returns Distribution\n",
        "ax = fig.add_subplot(gs[1, 1])\n",
        "sample_cols = min(4, len(fx_returns.columns))\n",
        "for col in fx_returns.columns[:sample_cols]:\n",
        "    ax.hist(fx_returns[col], bins=20, alpha=0.5, label=col, edgecolor='black')\n",
        "ax.set_xlabel('Monthly Return')\n",
        "ax.set_ylabel('Frequency')\n",
        "ax.set_title('Sample FX Returns Distributions', fontsize=12, fontweight='bold')\n",
        "ax.legend(fontsize=8)\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 5: Returns over time\n",
        "ax = fig.add_subplot(gs[1, 2])\n",
        "ax.plot(spx_ret.index, spx_ret, linewidth=1, alpha=0.7, color='darkblue')\n",
        "ax.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
        "ax.fill_between(spx_ret.index, 0, spx_ret,\n",
        "                where=(spx_ret>0), alpha=0.3, color='green', label='Positive')\n",
        "ax.fill_between(spx_ret.index, 0, spx_ret,\n",
        "                where=(spx_ret<0), alpha=0.3, color='red', label='Negative')\n",
        "ax.set_xlabel('Date')\n",
        "ax.set_ylabel('Return')\n",
        "ax.set_title('S&P 500 Returns Over Time', fontsize=12, fontweight='bold')\n",
        "ax.legend(fontsize=8)\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 6: Rolling volatility\n",
        "ax = fig.add_subplot(gs[2, 0])\n",
        "rolling_vol = spx_ret.rolling(window=12).std() * np.sqrt(12) * 100\n",
        "ax.plot(rolling_vol.index, rolling_vol, linewidth=2, color='darkred')\n",
        "ax.fill_between(rolling_vol.index, rolling_vol, alpha=0.3, color='darkred')\n",
        "ax.set_xlabel('Date')\n",
        "ax.set_ylabel('Annualized Volatility (%)')\n",
        "ax.set_title('S&P 500 Rolling 12-Month Volatility', fontsize=12, fontweight='bold')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 7: Scatter plot\n",
        "ax = fig.add_subplot(gs[2, 1])\n",
        "best_fx = spx_corr.index[0]\n",
        "ax.scatter(fx_returns[best_fx], spx_ret, alpha=0.5, s=30, edgecolors='black', linewidth=0.5)\n",
        "z = np.polyfit(fx_returns[best_fx], spx_ret, 1)\n",
        "p = np.poly1d(z)\n",
        "ax.plot(fx_returns[best_fx], p(fx_returns[best_fx]), \"r--\", linewidth=2)\n",
        "ax.set_xlabel(f'{best_fx} Return')\n",
        "ax.set_ylabel('SPX Return')\n",
        "ax.set_title(f'Best Correlation: {best_fx} vs SPX (r={spx_corr[best_fx]:.3f})',\n",
        "             fontsize=12, fontweight='bold')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 8: QQ Plot\n",
        "ax = fig.add_subplot(gs[2, 2])\n",
        "from scipy import stats\n",
        "stats.probplot(spx_ret, dist=\"norm\", plot=ax)\n",
        "ax.set_title('Q-Q Plot: SPX Returns vs Normal', fontsize=12, fontweight='bold')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.savefig('eda_analysis.png', dpi=300, bbox_inches='tight')\n",
        "print(\"  ✓ Saved: eda_analysis.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKHdXmJiYP4P"
      },
      "source": [
        "#Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXnoCuVJYRfJ"
      },
      "outputs": [],
      "source": [
        "X = fx_returns\n",
        "y = spx_ret\n",
        "\n",
        "# Train/test split\n",
        "split_idx = int(len(X) * 0.8)\n",
        "X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
        "y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
        "\n",
        "print(f\"  Train: {len(X_train)} | Test: {len(X_test)}\")\n",
        "\n",
        "# Scale\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# CV setup\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "max_components = min(15, X_train.shape[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ss_nvn4EZ4OQ"
      },
      "source": [
        "#PCR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqNYHP6wa0WG"
      },
      "outputs": [],
      "source": [
        "pca_full = PCA()\n",
        "pca_full.fit(X_train_scaled)\n",
        "\n",
        "cumsum_var = np.cumsum(pca_full.explained_variance_ratio_)\n",
        "n_95 = np.argmax(cumsum_var >= 0.95) + 1\n",
        "print(f\"  Components for 95% variance: {n_95}\")\n",
        "\n",
        "cv_scores = []\n",
        "for n in range(1, max_components):\n",
        "    pca_temp = PCA(n_components=n)\n",
        "    X_pca = pca_temp.fit_transform(X_train_scaled)\n",
        "    scores = cross_val_score(LinearRegression(), X_pca, y_train, cv=tscv, scoring='r2')\n",
        "    cv_scores.append(scores.mean())\n",
        "\n",
        "optimal_n_pca = np.argmax(cv_scores) + 1\n",
        "print(f\"  Optimal components: {optimal_n_pca} (CV R² = {max(cv_scores):.4f})\")\n",
        "\n",
        "pca = PCA(n_components=optimal_n_pca)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "pcr = LinearRegression().fit(X_train_pca, y_train)\n",
        "y_pred_pcr = pcr.predict(X_test_pca)\n",
        "\n",
        "r2_pcr = r2_score(y_test, y_pred_pcr)\n",
        "dir_acc_pcr = np.mean(np.sign(y_test) == np.sign(y_pred_pcr))\n",
        "print(f\"  R²: {r2_pcr:.4f} | Dir Acc: {dir_acc_pcr:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PLS"
      ],
      "metadata": {
        "id": "r5R_OoH1V-uh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2D0tqG3X1yMH"
      },
      "outputs": [],
      "source": [
        "print(\"\\n[STEP 5] Partial Least Squares...\")\n",
        "\n",
        "cv_scores_pls = []\n",
        "for n in range(1, max_components):\n",
        "    pls_temp = PLSRegression(n_components=n)\n",
        "    scores = cross_val_score(pls_temp, X_train_scaled, y_train, cv=tscv, scoring='r2')\n",
        "    cv_scores_pls.append(scores.mean())\n",
        "\n",
        "optimal_n_pls = np.argmax(cv_scores_pls) + 1\n",
        "print(f\"  Optimal components: {optimal_n_pls}\")\n",
        "\n",
        "pls = PLSRegression(n_components=optimal_n_pls)\n",
        "pls.fit(X_train_scaled, y_train)\n",
        "y_pred_pls = pls.predict(X_test_scaled).ravel()\n",
        "\n",
        "r2_pls = r2_score(y_test, y_pred_pls)\n",
        "dir_acc_pls = np.mean(np.sign(y_test) == np.sign(y_pred_pls))\n",
        "print(f\"  R²: {r2_pls:.4f} | Dir Acc: {dir_acc_pls:.2%}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lasso"
      ],
      "metadata": {
        "id": "kk9COA6eWKRI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wymku0-15kW"
      },
      "outputs": [],
      "source": [
        "print(\"\\n[STEP 6] Lasso Regression...\")\n",
        "\n",
        "lasso = LassoCV(cv=tscv, random_state=42, max_iter=10000)\n",
        "lasso.fit(X_train_scaled, y_train)\n",
        "y_pred_lasso = lasso.predict(X_test_scaled)\n",
        "\n",
        "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
        "dir_acc_lasso = np.mean(np.sign(y_test) == np.sign(y_pred_lasso))\n",
        "n_selected = (lasso.coef_ != 0).sum()\n",
        "\n",
        "print(f\"  Best alpha: {lasso.alpha_:.6f}\")\n",
        "print(f\"  Features selected: {n_selected}\")\n",
        "print(f\"  R²: {r2_lasso:.4f} | Dir Acc: {dir_acc_lasso:.2%}\")\n",
        "\n",
        "if n_selected > 0:\n",
        "    coefs = pd.Series(lasso.coef_, index=X_train.columns)\n",
        "    selected = coefs[coefs != 0].sort_values(key=abs, ascending=False)\n",
        "    print(f\"\\n  Selected features:\")\n",
        "    for feat, coef in selected.items():\n",
        "        print(f\"    {feat}: {coef:>+.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Results"
      ],
      "metadata": {
        "id": "6FZqClMEWQy1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJhTbk175dV6"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RESULTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    'Model': ['PCR', 'PLS', 'Lasso'],\n",
        "    'R²': [r2_pcr, r2_pls, r2_lasso],\n",
        "    'Dir_Acc': [dir_acc_pcr, dir_acc_pls, dir_acc_lasso]\n",
        "})\n",
        "\n",
        "print(\"\\n\" + results.to_string(index=False))\n",
        "print(f\"\\nBest model: {results.loc[results['R²'].idxmax(), 'Model']}\")\n",
        "\n",
        "# Create results visualization\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# Plot 1: Model comparison\n",
        "ax = axes[0, 0]\n",
        "colors = ['blue', 'green', 'red']\n",
        "ax.bar(results['Model'], results['R²'], color=colors, alpha=0.7)\n",
        "ax.set_ylabel('R² Score')\n",
        "ax.set_title('Model Performance', fontweight='bold')\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "for i, (m, r2) in enumerate(zip(results['Model'], results['R²'])):\n",
        "    ax.text(i, r2 + 0.01, f'{r2:.4f}', ha='center', fontweight='bold')\n",
        "\n",
        "# Plot 2: PCA variance\n",
        "ax = axes[0, 1]\n",
        "ax.bar(range(1, len(pca_full.explained_variance_ratio_)+1),\n",
        "       pca_full.explained_variance_ratio_, alpha=0.7)\n",
        "ax.plot(range(1, len(cumsum_var)+1), cumsum_var, 'r-o', linewidth=2, markersize=3)\n",
        "ax.axvline(x=optimal_n_pca, color='b', linestyle='--')\n",
        "ax.set_xlabel('Component')\n",
        "ax.set_ylabel('Variance')\n",
        "ax.set_title('PCA Explained Variance', fontweight='bold')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Plots 3-4: Actual vs Predicted\n",
        "for idx, (name, pred, color) in enumerate([('PCR', y_pred_pcr, 'blue'),\n",
        "                                             ('Lasso', y_pred_lasso, 'red')]):\n",
        "    ax = axes[1, idx]\n",
        "    ax.scatter(y_test, pred, alpha=0.6, s=40, color=color, edgecolors='black', linewidth=0.5)\n",
        "    min_val, max_val = min(y_test.min(), pred.min()), max(y_test.max(), pred.max())\n",
        "    ax.plot([min_val, max_val], [min_val, max_val], 'k--', lw=2)\n",
        "    ax.set_xlabel('Actual')\n",
        "    ax.set_ylabel('Predicted')\n",
        "    ax.set_title(f'{name}: Actual vs Predicted', fontweight='bold')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    r2_val = r2_score(y_test, pred)\n",
        "    ax.text(0.05, 0.95, f'R² = {r2_val:.4f}', transform=ax.transAxes,\n",
        "            fontsize=11, va='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('model_results.png', dpi=300, bbox_inches='tight')\n",
        "print(\"\\n✓ Saved: model_results.png\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ANALYSIS COMPLETE!\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nDataset: {len(X)} months from {X.index.min().date()} to {X.index.max().date()}\")\n",
        "print(f\"High FX correlations: {len(high_corr_pairs)} pairs\")\n",
        "print(f\"Best model: {results.loc[results['R²'].idxmax(), 'Model']} (R² = {results['R²'].max():.4f})\")\n",
        "print(\"=\"*80)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}